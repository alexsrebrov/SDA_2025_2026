# Семинар №7 по СДА - Хеш таблици

## Въведение в хеш таблици
Ще разгледаме следният проблем - имаме някаква колекция от елементи, които искаме да бъдат адресирани. Представете си нещо подобно на вектор, в който имаме елементи от тип Т и ключове за адресация - индексите на вектора. Какво става, когато искаме да ползваме произволни такива ключове за, нека кажем, 10 елемента? Можем да създадем функция, която е биекция между тези 10 ключа и първите 10 индекса на вектора (0, 1, ... 9) и така ще си решим проблема - ще имаме колеция, която можем да адресираме с помощта на тези 10 ключа. Този подход работи добре, когато множеството от възможни ключове е "малко". Какво ще стане обаче, ако това мноежство е от 1000, 5000, дори безкраен брой елементи? 

## Какво е хеш функция?
Хеш функция наричаме функция, която може да приема произволно голям вход от дадено (безкрайно) множество и връща като резултат стойност с фиксиран размер (от някакво крайно множество). Тази стойност наричаме хеш код на получените входни данни. 

Нека например нашата функция приема прозиволни string-ове и връща числа в диапазон от 0 до 500. Доста лесно можем да заключим, че по този начин можем да използваме string-ове като ключове, с които да адресираме някакви данни (най-много 500 такива) - примерно колекция от оценки, за която ключът е името на студента:

```c++ 
grades["Pesho"] = 5.50 // Could be expressed like grades[hash("Pesho")] = 5.50, where grades is a vector
grades["Gosho"] = 4.75
```

Разбира се, има множество проблеми, за които веднага можем да се сетим. Първо, за да бъде смислено цялото това преобразуване, функцията трябва да бъде детерминистична. Какво означава това? Ами, най-просто казано - за еднакъв вход, тя трябва да връща еднакъв изход (x == y => hash(x) == hash(y)).

Друг проблем би бил очевиден от следния пример: Нека дефинираме hash(str) = 0. Ако опитаме да работим с `grades["Pesho"]` и `grades["Gosho"]`, данните, които тези два ключа адресират, ще бъдат едни и същи - тези на индекс 0 в колекцията.

Следователно, свойство което бихме искали от хеш функцията е за x != y => hash(x) != hash(y) (Функцията да бъде инекция). Но за жалост, това изискване е невъзможно да бъде изискано. Защо? Ами, поради простото съображение, че домейнът на функцията е безкрайно множество, а кодомейнът - крайно. Следователно няма как да се конструира такава инекция. Все пак, ще искаме за максимално много стойности x != y това твърдение да е изпълнено.

(**Side note:** допълнително е добре хеширащата функция да "разпръсква" данните в целия интервал. Тоест, ако x и y са някакви близки стойности, то hash(x) и hash(y) да не са непременно близки)

От фактът, че функцията няма как да бъде инективна, ясно се вижда, че тя не е обратима (няма как от hash да получим еднозначно оригиналният отговор).

Последното изискване, което ще поставим върху нашата хешираща функция е тя да работи "бързо", за да не променя асимптотиката на колекциите, които използват хеширане.

## `Хеш таблица`
Хеш таблицата е вид колекция, която позволява адресация на данни (от тип **Т**) с помощта на избран от потребителя тип на ключа (тип **К**).

Колекцията разполага с конкретен капацитет **N**, както и с хешираща функция **hash(K)**, която връща стойности в интервала [0, N). 

Повечето от проблемите на тази идея и техните решения разгледахме в дефиницията на хеш функция. Остана единствено да решим следният казус - какво става, когато два ключа имат еднакъв хеш? 

Събитието два различни ключа да имат еднакъв хеш код се нарича "колизия" (от английски - сблъскване). За да се справим по начало с него, освен функция за хеширане, ще ни трябва и функция за различаване на двата ключа (функция за сравнение). Който е писал на Java знае, че предефинирането на функцията **hashCode** върви винаги ръка за ръка с функцията **equals**. 

## Справяне с колизии
Нека разгледаме кои са най-честите стратегии за справяне с колизии

### `Separete chaining`
Идеята тук е да пазим свързан списък с елементите с еднакъв хеш код. Нашата основна колекция е от **Node*** елементи, които играят роля на head указател за всеки свъразн списък. 

Когато трябва да се добави нов елемент към колекция, той се добавя в края на свързаният списък, намиращ се на получената от хеширането на ключа позиция.

Търсенето на елемент се случва в две фази - хешираме ключа (чрез **hashCode** функцията), за да видим в кой свързан списък да го търсим, и след това обхождаме свързания списък, за да го намерим (чрез **equals** функцията).

Премахването ще бъде сходно на търсенето, но с добавената стъпка да се пренасочат указателите и да се изтрие от паметта клетката, ако я има.

Каква е сложността на всяка от тези операции? Ами, зависи от това колко големи ще позволим да бъдат свързаните списъци. За да я минимизираме максимално, ще поискаме отношението между броя клетки в основната колекция (броя свързани списъци) и броя клетки сумарно измежду всички свързани списъци (**load factor**) да бъде в някакво константно отношение (по-точно - в някакъв диапазон между две константи). След напускането на този диапазон, колекцията се преуразмерява и всички клетки се хешират и попълват наново.

Проблемът на тази имплементация е, че използваме свързани списъци и цялата идея да адресираме паметта чрез тези ключове леко се губи, тъй като силата на подобен вид колеции е именно, че разчитаме на непрекъснат блок памет, който може да се кешира (**locallity**). В случая това свойство се губи.

```
Buckets:
 ┌─────┬─────┬─────┬─────┬─────┐
 │  0  │  1  │  2  │  3  │  4  │
 ├─────┼─────┼─────┼─────┼─────┤
 │  -  │ A→B │  C  │D→E→F│  -  │
 └─────┴─────┴─────┴─────┴─────┘
```

### `Open addressing`
Open addressing е метод за разрешаване на колизии в хеш таблици, при който всички елементи се съхраняват директно в масив, без допълнителни структури като свързани списъци.
Когато двa ключa получат една и съща начална позиция (индекс), структурата използва последователност от алтернативни позиции, наречена probe sequence, за да намери свободна клетка.

#### Linear Probing
```
h(k), h(k)+1, h(k)+2, h(k)+3, ...
```

```
Insert key → index 3 (occupied)

Проби:
3 X
4 X
5 O  ← свободно
```

#### Quadratic Probing
```
h(k) + 1², h(k) + 2², h(k) + 3², ...
```

```
h=3
проби: 3 → 4 → 7 → 12 → ...
```

#### Double Hashing
```
pos = (h1(key) + i * h2(key)) % m
```

```
h1(k)=3, h2(k)=7
последователност: 3, 10, 17, 24...
```

#### Multiplicative Probing (i, 2i, 3i…)
```
i, 2*i, 3*i, 4*i ...
```

### Сложности при Separate Chaining
Всеки bucket е списък (често linked list).
Колизиите се държат в списък → обхождане вътре в кофата.

```
Операция	Average	 Worst-case
Insert	    O(1)	    O(n)
Search	    O(1)	    O(n)
Delete	    O(1)	    O(n)
```

Защо?

При добра хеш функция → кофите са къси → O(1).

При най-лошия случай всички елементи отиват в една кофа → става списък → O(n).

### Сложности при Open Addressing
Всички елементи са в масива.
Търси се следваща позиция по probe sequence при колизия.

```
Операция	Average	          Worst-case
Insert	   O(1) амортизирано    O(n)
Search	   O(1) амортизирано    O(n)
Delete	   O(1) амортизирано    O(n)
```

Защо?

При нисък load factor (α < 0.7) → много празни клетки → пробването е кратко → O(1).

При почти пълна таблица или клъстери → може да се наложи обхождане на почти целия масив → O(n).


## STL имплементации
```c++
std::unordered_map<K, V> hashMap;
std::unordered_set<V> hashSet;
```

---
## Задачи
[1. Маската на зоро](https://www.hackerrank.com/contests/sda-hw-7-2022/challenges/zoros-mask)

[2. Isomorphic strings](https://leetcode.com/problems/isomorphic-strings/description/)

[3. Group Anagrams](https://leetcode.com/problems/group-anagrams/description/)

[4. Subarrays Sum K](https://leetcode.com/problems/subarray-sum-equals-k/)

[5. 0-1 Subarray](https://www.hackerrank.com/contests/sda-homework-9/challenges/0-1-1/)

[6. Longest Consecutive Sequence](https://leetcode.com/problems/longest-consecutive-sequence/description/)

[7. DNA Sequence](https://leetcode.com/problems/repeated-dna-sequences/)
